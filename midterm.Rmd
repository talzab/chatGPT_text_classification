---
title: "text analysis midterm"
author: "Tilina Alzaben"
date: "2023-10-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
```

```{r}
data <- read.csv("midterm_mini_intros.csv")
knitr::kable(substr(data$text[1], start = 1, stop = 1000), col.names = "Sample of Text")
```
```{r}
# Creating a Corpus 
wc <- corpus(data)

# Returns the total and unique number of tokens, as well as number of sentences.
knitr::kable(head(wc %>% summary()), caption = "Partial Sample of Writing Corpus.")
```

```{r}
# Document Variables 
doc_categories <- str_extract(data$doc_id, "^[a-z]+")
knitr::kable(doc_categories %>% unique(), col.names = "Writing Level")

# Assining the Levels Back
docvars(wc, field = "text_type") <- doc_categories
knitr::kable(head(wc %>% summary()), caption = "Partial summary of sample corpus.")
```

```{r}
# Tokenizing 
wc_tokens <- tokens(wc, include_docvars = TRUE, remove_punct = TRUE, remove_numbers = TRUE, 
                    remove_symbols = TRUE, what = "word")
wc_tokens <- tokens_tolower(wc_tokens)
wc_tokens <- tokens_select(wc_tokens, pattern = stopwords("en"), selection = "remove")
```

```{r}
# Checking for Multi-Word Expressions
knitr::kable(tail(multiword_expressions), col.names = "", caption = "Multi-word expressions.")
sc_tokens <- tokens_compound(wc_tokens, pattern = phrase(multiword_expressions))
```


```{r}
# Create a Document Feature Matrix
wc_dfm <- dfm(wc_tokens)
prop_dfm <- dfm_weight(wc_dfm, scheme = "prop")
```

```{r}
# More Frequent Tokens
freq_df <- textstat_frequency(wc_dfm) %>% data.frame(stringsAsFactors = F)
knitr::kable(freq_df[1:10,], caption = "The 10 most frequent tokens in the sample corpus.")
```

```{r}
# Dispersion of All Tokens
d <- dispersions_all(wc_dfm)
knitr::kable(head(d), digits = 3, caption = "Dispersion measures for all tokens.", "simple")

# Frequency Table
ft <- frequency_table(wc_tokens)
knitr::kable(head(ft), digits = 3, caption = "Measures for all tokens.", "simple")

ggplot(freq_df %>% 
         filter(rank < 101), aes(x = rank, y = frequency)) +
  geom_point(shape = 1, alpha = .5) +
  theme_classic() +
  ylab("Absolute frequency") +
  xlab("Rank")
```
```{r}
# Keyness
corpus_comp <- ntoken(wc_dfm) %>% 
  data.frame(Tokens = .) %>%
  rownames_to_column("Text_Type") %>%
  mutate(Text_Type = str_extract(Text_Type, "^[a-z]+")) %>%
  group_by(Text_Type) %>%
  summarize(Texts = n(),
    Tokens = sum(Tokens)) %>%
  mutate(Text_Type = c("ChatGPT", "Published", "Student")) %>%
  rename("Text-Type" = Text_Type) %>%
  janitor::adorn_totals()

kableExtra::kbl(corpus_comp, caption = "Composition", booktabs = T, linesep = "") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()
```
```{r}
chatgpt_kw <- textstat_keyness(wc_dfm, docvars(wc_dfm, "text_type") == "chatgpt", measure = "lr")

kableExtra::kbl(head(chatgpt_kw), caption = "Tokens with the highest keyness values in ChatGPT text-type compared to the rest of the sample corpus.", booktabs = T, linesep = "", digits = 2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()
```

```{r}
# Creating a Sub-Corpa
sub_dfm <- dfm_subset(wc_dfm, text_type == "chatgpt" | text_type == "student")
sub_dfm <- dfm_trim(sub_dfm, min_termfreq = 1)

student_kw <- textstat_keyness(sub_dfm, docvars(sub_dfm, "text_type") == "student", measure = "lr")
kableExtra::kbl(head(student_kw), caption = "Tokens with the highest keyness values in student text-type when compared to ChatGPT text-type.", booktabs = T, linesep = "", digits = 2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()
```

```{r}
chatgpt_kw <- textstat_keyness(sub_dfm, docvars(sub_dfm, "text_type") == "chatgpt", measure = "lr")

kableExtra::kbl(tail(chatgpt_kw), caption = "Tokens with the lowest keyness values in the ChatGPT text-type when compared to the Student text-type.", booktabs = T, linesep = "", digits = 2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()
```

```{r}
# The Effect Size
chatgpt_dfm <- dfm_subset(wc_dfm, text_type == "chatgpt") %>% dfm_trim(min_termfreq = 1)
student_dfm <- dfm_subset(wc_dfm, text_type == "student") %>% dfm_trim(min_termfreq = 1)

chatgpt_kw <- keyness_table(chatgpt_dfm, student_dfm)

kableExtra::kbl(head(chatgpt_kw), caption = "Tokens with the highest keyness values in the ChatGPT text-type when compared to the Student text-type.", booktabs = T, linesep = "", digits = 2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()
```

```{r}
# Keyness Pairs
published_dfm <- dfm_subset(wc_dfm, text_type == "published") %>% dfm_trim(min_termfreq = 1)
kp <- keyness_pairs(chatgpt_dfm, student_dfm, published_dfm)

knitr::kable(head(kp), caption = "Pairwise comparisions of chatgpt (target) vs. student (reference), chatgpt (target) vs. published (reference), and student (target) vs. published (reference).", 
             digits = 2, booktabs = T) %>% 
  kableExtra::kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```
```{r}
kk <- key_keys(chatgpt_dfm, student_dfm)
knitr::kable(head(kk), digits = 2, "simple", caption = "Key key words when comparing ChatGPT text-type to the Student text-type.")
```



